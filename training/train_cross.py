from dataclasses import dataclass
from early_stopping import EarlyStopping
from cube_bindings import Cube
import torch
import torch.nn as nn
from torch import Tensor

@dataclass
class TrainConfig:
    scramble_len :int
    epochs :int
    val_num_batches :int
    batch_size :int
    lr :float
    device: torch.device
    optimizer :torch.optim.Optimizer
    early_stopping :EarlyStopping
    criterion: nn.Module = nn.CrossEntropyLoss()

class Trainer:
    def __init__(self, cube : Cube, config :TrainConfig, model :nn.Module) -> None:

        #unpack train config
        self.epochs = config.epochs
        self.batch_size = config.batch_size
        self.lr = config.lr
        self.device = config.device
        self.optimizer = config.optimizer(model.parameters(), lr=config.lr)
        self.criterion = config.criterion
        self.scramble_len = config.scramble_len

        # setup early stopping
        self.early_stopping = config.early_stopping

        # python bindings to the cube rust program
        self.cube = cube 

        # The model will output a prediction between 12 classes, one for each possible move
        # This list will be used to convert the output of the model to a string representation of the move
        self.moves = ["U", "U'", "D", "D'", "L", "L'", "R", "R'", "F", "F'", "B", "B'", ""]

        # model
        self.model = model
        self.model.to(self.device)

        # train stats
        self.train_loss = [ 0 for _ in range(self.epochs) ]
        self.val_loss = [ 0 for _ in range(self.epochs) ]


    def train(self) -> None:
        """
        The train() function works differently than a typical pytorch training loop. This is because of the semi-reinforced nature of 
        training. 

        The loss is predicated on the model predicting the next correct move in the solution as defined by the solution generated by the 
        cross solver function. This means that at the start of each epoch, a new batch of cube_states, scrambles, and cross solutions will
        be generated to serve as the training data of the model. 
        """

        for i in range(self.epochs):
            
            # generate a batch of training data
            cube_states, scrambles = self.get_batch()

            print(f'cube_states shape: {cube_states.shape}')

            # This is a list of list of strings. (each str is an individual move)
            true_solutions = [self.cube.solve_cross(scramble).split() for scramble in scrambles] 
    
            # append empty strings to the any actual solutions that are less than the longest actual solution list until they match that length
            max_solution_len = max([len(solution) for solution in true_solutions])
            for j in range(self.batch_size):
                while len(true_solutions[j]) < max_solution_len:
                    true_solutions[j].append("")

            # using python string methods, replace '' with ' in the true solutions
            true_solutions = [ [move.replace("'", "") for move in solution] for solution in true_solutions ]

            # initialize the model solutions to be empty strings
            model_solutions = [ "" for _ in range(self.batch_size) ]
                    
            print(f'length of max solution: {max_solution_len}')


            # iterate through the moves of true solutions
            for move in range(max_solution_len):

                # forward pass 
                print(f'cube_states shape: {cube_states.shape}')

                outputs = self.model(cube_states) # probabilitiy distribution over the 12 possible moves
                print(f'outputs shape: {outputs.shape}')

                pred = torch.argmax(outputs, dim=1) # index of the most likely move
                print(f'pred shape: {pred.shape}')


                # update scrambles to include the models pred
                moves = [ self.moves[pred[i]] for i in range(self.batch_size) ] # convert move pred to string representation
                all_moves_made = [ " ".join([scrambles[i], moves[i]]) for i in range(self.batch_size) ]
                next_cube_state = self.cube.apply_moves(all_moves_made).unsqueeze(1).unsqueeze(1) # <-- add channels and time series dimmensions
                
                # concat the next cube state to the cube states along the time-step dimmension
                cube_states = torch.cat((cube_states, next_cube_state), dim=1)
                
                

                # update true solutions to include the models pred
                model_solutions = [ model_solutions[i] + moves[i] for i in range(self.batch_size) ] 

                # convert the true solutions to a tensor of ints
                correct_moves = torch.tensor([ self.moves.index(true_solutions[i][move]) for i in range(self.batch_size) ])

                # calculate loss
                loss = self.criterion(outputs, correct_moves)

                # backprop
                loss.backward()
                self.optimizer.step()
                self.optimizer.zero_grad()

                # update train loss
                self.train_loss[i] += loss.item()

            # average the epoch loss over the number of moves in the solution
            self.train_loss[i] /= max_solution_len

            print(f'epoch: {i} | train loss: {self.train_loss[i]}')



    def get_batch(self) -> (Tensor, list[str]):
        '''
        gen_batch() calls on the Cube python bindings to generate a batch of scrambled cube states and their corresponding scrambles.

        All of the additional logic is used to check that all of the scrambles generated by the solved are solvable by the cross solver 
        program within Cube. If any of the scrambles are not solveable, then they are removed from the batch and replaced with new ones.

        The function returns a tuple of the cube states and their corresponding scrambles. 
        NOTE: The cube state is a torch Tensor of shape (batch_size, time_steps, channels, depths, width, height)
        '''

        all_solved = 0

        # This lambda function is used to check if the scramble is solvable by the cross solver program
        check_solution = lambda scramble, solution : self.cube.is_cross_solved(" ".join([scramble, solution]))

        while not all_solved:

            cube_states, scrambles = self.cube.generate_data(self.batch_size, self.scramble_len)

            cross_solutions = [ self.cube.solve_cross(scramble) for scramble in scrambles ]
            is_cross_solved = [ check_solution(scrambles[i], solution) for (i, solution) in enumerate(cross_solutions)]

            # check that all of the scrambles are solvable by the cross solver program
            if not all(is_cross_solved):

                # Use boolean indexing to filter cube_states and scrambles to only include the ones that are solvable
                solvable_cube_states = cube_states[torch.tensor(is_cross_solved)]
                solvable_scrambles  = [ scrambles[i] for (i, is_true) in enumerate(is_cross_solved) if is_true ]

                # ensure that each batch is the correct size and that all of the scrambles are solvable
                while not solvable_cube_states.shape[0] == self.batch_size:

                    # generate new scrambles and cube states
                    cube_states, scrambles = self.cube.generate_data(self.batch_size, self.scramble_len)
                    cross_solutions = [ self.cube.solve_cross(scramble) for scramble in scrambles ]
                    is_cross_solved = [ check_solution(scrambles[i], solution) for (i, solution) in enumerate(cross_solutions)]

                    # Use boolean indexing to filter cube_states and scrambles to only include the ones that are solvable
                    new_solvable_cube_states = cube_states[torch.tensor(is_cross_solved)]
                    new_solvable_scrambles  = [ scrambles[i] for (i, is_true) in enumerate(is_cross_solved) if is_true ]

                    # concatenate the new solvable cube states and scrambles to the old ones
                    for i in range(self.batch_size - solvable_cube_states.shape[0]):
                        solvable_cube_states = torch.cat((solvable_cube_states, new_solvable_cube_states[i].unsqueeze(0)))
                        solvable_scrambles.append(new_solvable_scrambles[i])    

                # unsqueeze is used to add the channels and time series dimmensions
                return solvable_cube_states.unsqueeze(1).unsqueeze(1), solvable_scrambles

            else : # unsqueeze is used to add the channels and time series dimmensions
                return cube_states.unsqueeze(1).unsqueeze(1), scrambles






